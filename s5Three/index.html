<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="apple-touch-icon" href="apple-touch-icon.png">

  <!--meta content-->
  
  <meta name="author" content="Ruth John (@rumyra)">
  <meta name="dcterms.rightsHolder" content="Built by Ruth John, United Kingdom, 2016">
  <title>VJ Tracks | Rumyra</title>
  <meta name="description" content="">
  <!-- <link rel="stylesheet" href="style.css"> -->

  <script src="d3.min.js"></script>
  <script src="three.min.js"></script>
  <script src="js/lib/Projector.js"></script>
  <script src="js/lib/CanvasRenderer.js"></script>

  <!--include if you want modenizr (rest of scripts just before </body>)
  <script src="js/vendor/modernizr-2.6.2.min.js"></script>
  -->
  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
    }
    body {
      background: #111;
    }
  </style>
</head>
<body>

<div id="screen"></div>

<script type="text/javascript">
var audioApi = new window.AudioContext;
var screen = document.querySelector('#screen');

// variables
var audioBuffer,
    analyserNode,
    frequencyData = new Uint8Array(256);

// create an audio API analyser node and connect to source
function createAnalyserNode(audioSource) {
  analyserNode = audioApi.createAnalyser();
  analyserNode.fftSize = 512;
  audioSource.connect(analyserNode);
}

// getUserMedia success callback -> pipe audio stream into audio API
function gotStream(stream) {
    // Create an audio input from the stream.
    var audioSource = audioApi.createMediaStreamSource(stream);
    createAnalyserNode(audioSource);
    animate();
}

// pipe in analysing to getUserMedia
navigator.mediaDevices.getUserMedia({ audio: true, video: false })
  .then(gotStream);

// three.js stuff ~~~~~~~~~~~~~~~~~~~~~~
var camera, 
  scene,
  renderer,
  raycaster;
var PI2 = Math.PI*2;

var programFill = function ( context ) {
  context.beginPath();
  context.arc( 0, 0, 0.5, 0, PI2, true );
  context.fill();
};

var programStroke = function ( context ) {
  context.lineWidth = 0.025;
  context.beginPath();
  context.arc( 0, 0, 0.5, 0, PI2, true );
  context.stroke();
};

initThree();

function initThree() {
  camera = new THREE.PerspectiveCamera( 70, window.innerWidth / window.innerHeight, 1, 10000 );
  camera.position.set( 0, 300, 500 );

  scene = new THREE.Scene();

  raycaster = new THREE.Raycaster();

  renderer = new THREE.CanvasRenderer();
  renderer.setClearColor( 0xf0f0f0 );
  renderer.setPixelRatio( window.devicePixelRatio );
  renderer.setSize( window.innerWidth, window.innerHeight );
  screen.appendChild( renderer.domElement );
}

function createParticle(d,i) {
  var particle = new THREE.Sprite( new THREE.SpriteCanvasMaterial( { color: Math.random() * 0x808080 + 0x808080, program: programStroke } ) );
    particle.position.x = Math.random() * 800 - 400;
    particle.position.y = Math.random() * 800 - 400;
    particle.position.z = Math.random() * 800 - 400;
    particle.scale.x = particle.scale.y = Math.random() * 20 + 20;
    scene.add( particle );
}


// enter and exit
var canvas = d3.select('canvas');
var radius = 600, theta = 0;
var dataBinding = canvas.selectAll('custom.bubble');

function drawBubbles() {

  analyserNode.getByteFrequencyData(frequencyData);

  for (var i = frequencyData.length - 1; i >= 0; i--) {
    createParticle(frequencyData[i],i);
  }
  
}

function render() {
  // rotate camera
  theta += 0.1;
  camera.position.x = radius * Math.sin( THREE.Math.degToRad( theta ) );
  camera.position.y = radius * Math.sin( THREE.Math.degToRad( theta ) );
  camera.position.z = radius * Math.cos( THREE.Math.degToRad( theta ) );
  camera.lookAt( scene.position );
  camera.updateMatrixWorld();

  renderer.render(scene,camera);
}

function animate() {
  requestAnimationFrame(animate);
  render();
  drawBubbles();
}


</script>
</body>
</html>
